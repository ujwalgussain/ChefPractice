Thread Safety:
A class is thread-safe if it behaves correctly when accessed from multiple threads,
regardless of the scheduling or interleaving of the execution of those threads by the runtime environment,
and with no additional synchronization or other coordination on the part of the calling code.

Stateless objects are always thread-safe.

Ex: Not Thread Safe
@NotThreadSafe
public class UnsafeCountingFactorizer implements Servlet {
    private long count = 0;
    public long getCount() { return count; }
    public void service(ServletRequest req, ServletResponse resp) {
        BigInteger i = extractFromRequest(req);
        BigInteger[] factors = factor(i);
        ++count; //This is a compound operation
        encodeIntoResponse(resp, factors);
    }
}
While the increment operation, ++count, may look like a single action because of its compact syntax,
it is not atomic, (it does not execute as a single operation).
Instead, it has three discrete operations:
            fetch the current value,
            add one to it, and
            write the new value back.
This is an example of a read-modify-write operation, in which the resulting state is derived from the previous state.
what can happen if two threads try to increment a
counter simultaneously without synchronization. If the counter is initially 9, with
some unlucky timing each thread could read the value, see that it is 9, add one to
it, and each set the counter to 10. This is clearly not what is supposed to happen;
an increment got lost along the way, and the hit counter is now permanently off
by one.
The possibility of incorrect results in the presence of unlucky timing is so important
in concurrent programming that it has a name: a race condition.
    Race Conditions:
    A race condition occurs when the correctness of a computation depends
    on the relative timing or interleaving of multiple threads by the runtime; in other
    words, when getting the right answer relies on lucky timing.4 The most common
    type of race condition is check-then-act, where a potentially stale observation is
    used to make a decision on what to do next.

   check-then-act:  you observe something to be true (file X doesn’t exist)
                    and then take action based on that observation (create X); but in fact the
                    observation could have become invalid between the time you observed it and the
                    time you acted on it (someone else created X in the meantime), causing a problem
                    (unexpected exception, overwritten data, file corruption).
   Example: race conditions in lazy initialization
        @NotThreadSafe
        public class LazyInitRace {
            private ExpensiveObject instance = null;
            public ExpensiveObject getInstance() {
                if (instance == null)
                    instance = new ExpensiveObject();
                return instance;
            }
        }

        LazyInitRace has race conditions that can undermine its correctness. Say that
        threads A and B execute getInstance at the same time. A sees that instance
        is null, and instantiates a new ExpensiveObject. B also checks if instance is
        null. Whether instance is null at this point depends unpredictably on timing,
        including the vagaries of scheduling and how long A takes to instantiate the ExpensiveObject
        and set the instance field. If instance is null when B examines
        it, the two callers to getInstance may receive two different results, even though
        getInstance is always supposed to return the same instance.

        Operations A and B are atomic with respect to each other if, from the
        perspective of a thread executing A, when another thread executes B,
        either all of B has executed or none of it has. An atomic operation is one
        that is atomic with respect to all operations, including itself, that operate
        on the same state.


        @NotThreadSafe
        public class UnsafeCachingFactorizer implements Servlet {
            private final AtomicReference<BigInteger> lastNumber= new AtomicReference<BigInteger>();
            private final AtomicReference<BigInteger[]> lastFactors=new AtomicReference<BigInteger[]>();
            public void service(ServletRequest req, ServletResponse resp) {
                BigInteger i = extractFromRequest(req);
                if (i.equals(lastNumber.get()))
                    encodeIntoResponse(resp, lastFactors.get());
                else {
                    BigInteger[] factors = factor(i);
                    lastNumber.set(i);
                    lastFactors.set(factors);
                    encodeIntoResponse(resp, factors);
                }
            }
        }
        Note: To preserve state consistency, update related state variables in a single atomic operation.


    Intrinsic Locks:
        Java provides a built-in locking mechanism for enforcing atomicity: the synchronized
        block. (There is also another critical aspect to locking and other synchronization
        mechanisms—visibility—which is covered in Chapter 3.) A synchronized
        block has two parts: a reference to an object that will serve as the lock, and a
        block of code to be guarded by that lock. A synchronized method is a shorthand
        for a synchronized block that spans an entire method body, and whose lock is
        the object on which the method is being invoked. (Static synchronized methods
        use the Class object for the lock.)
        synchronized (lock) {
        // Access or modify shared state guarded by lock
        }

        Every Java object can implicitly act as a lock for purposes of synchronization;these built-in locks are called intrinsic locks or monitor locks.
        This Lock id ACQUIRED BEFORE ENTERING the sync block and RELEASED upon EXITING(normally/exception) the block.

        Intrinsic locks in Java act as mutexes (or mutual exclusion locks), which means that at most one thread may own the lock.
        When thread A attempts to acquire a lock held by thread B, A must wait, or block, until B releases it.
        If B never releases the lock, A waits forever.

        @ThreadSafe
        public class SynchronizedFactorizer implements Servlet {
            @GuardedBy("this") private BigInteger lastNumber;
            @GuardedBy("this") private BigInteger[] lastFactors;
            public synchronized void service(ServletRequest req, ServletResponse resp) {
                BigInteger i = extractFromRequest(req);
                if (i.equals(lastNumber))
                    encodeIntoResponse(resp, lastFactors);
                else {
                    BigInteger[] factors = factor(i);
                    lastNumber = i;
                    lastFactors = factors;
                    encodeIntoResponse(resp, factors);
                }
            }
        }

        Reentrancy
        When a thread requests a lock that is already held by another thread, the requesting thread blocks.
        Intrinsic locks are REENTRANT, if a thread tries to acquire a lock that it already holds, the request succeeds.
        Reentrancy means that locks are acquired on a per-thread rather than per-invocation basis.
        Reentrancy is implemented by associating with each lock an acquisition count and an owning thread.
        When the count is zero, the lock is considered unheld.
        When a thread acquires a previously unheld lock, the JVM records the owner and sets the acquisition count to one.
        If that same thread acquires the lock again, the count is incremented, and when the owning thread exits the synchronized block,
        the count is decremented.
        When the count reaches zero, the lock is released.

        Ex:
            public class ReentrancyUsingSynchronized {
                public static void main(String[] args) {
                    String s="123";
                    Runnable r = () ->{
                        synchronized (s)
                        {
                            System.out.println("1st Lock Acquired");
                            synchronized (s) {
                                System.out.println("2nd Lock Acquired");
                                synchronized (s)
                                {
                                    System.out.println("3rd Lock Acquired");
                                }
                                System.out.println("3rd Lock Released");
                            }
                            System.out.println("2nd Lock Released");
                        }
                        System.out.println("1st Lock Released");
                    };
                    new Thread(r).start();
                }
            }

            Output:
            1st Lock Acquired
            2nd Lock Acquired
            3rd Lock Acquired
            3rd Lock Released
            2nd Lock Released
            1st Lock Released
        Need for Reentrancy:

        Reentrancy saves us from deadlock in situations like this.

        public class Widget {
            public synchronized void doSomething() {
            ...
            }
        }
        public class LoggingWidget extends Widget {
            public synchronized void doSomething() {
                System.out.println(toString() + ": calling doSomething");
                super.doSomething();
            }
        }

        Guarding state With locks:
        Compound actions on shared state, such as incrementing a hit counter (read-modify-write) or lazy initialization (check-then-act),
        must be made atomic to avoid race conditions.
        Holding a lock for the entire duration of a compound action can make that compound action atomic.
        However, just wrapping the compound action with a synchronized block is not sufficient; if synchronization is used to
        coordinate access to a variable, it is needed everywhere that variable is accessed.
        Further, when using locks to coordinate access to a variable, the same lock must be used wherever that variable is accessed.

        It is a common mistake to assume that synchronization needs to be used only
        when writing to shared variables; this is simply not true.

        Conclusion:
            For each mutable state variable that may be accessed by more than one thread,
            all accesses to that variable must be performed with the same lock held.
            In this case, we say that the variable is guarded by that lock.

            Acquiring the lock associated with an object does not prevent other threads from accessing that
            object—the only thing that acquiring a lock prevents any other thread from doing is acquiring that same lock

            Every shared, mutable variable should be guarded by exactly one lock. Make it clear to maintainers which lock that is.
            To understand this consider the following Ex:
                lastNumber & lastFactors is guarded by invoking Object itself.
                If we would have used 2 different Locks then it would have lead to inconsistency.
            @ThreadSafe
            public class SynchronizedFactorizer implements Servlet {
                        @GuardedBy("this") private BigInteger lastNumber;
                        @GuardedBy("this") private BigInteger[] lastFactors;
                        public synchronized void service(ServletRequest req, ServletResponse resp) {
                            BigInteger i = extractFromRequest(req);
                            if (i.equals(lastNumber))
                                encodeIntoResponse(resp, lastFactors);
                        else {
                                BigInteger[] factors = factor(i);
                                lastNumber = i;
                                lastFactors = factors;
                                encodeIntoResponse(resp, factors);
                        }
                }
            }
        Not all data needs to be guarded by locks—only mutable data that will be accessed from multiple threads

        If synchronization is the cure for race conditions, why not just declare every method synchronized?
        Consider the Following Ex:

        package MultithreadingSample;

        import java.util.Vector;

        public class VectorSynchDisadvCheck {
            public static void main(String[] args) {
                Vector<Integer> v = new Vector<>();
                Runnable r = ()->{
                    int i=1;
                    while(i<=3)
                    {
                        int attempts=0;
                            if(!v.contains(i)) {
                                try {
                                    Thread.sleep(100);
                                } catch (InterruptedException e) {
                                    e.printStackTrace();
                                }
                                v.add(i);
                                System.out.println(Thread.currentThread().getName() + " added " + i);
                            }i++;
                    }
                    System.out.println(Thread.currentThread().getName()+" printed "+ v);
                };
                new Thread(r,"T1").start();
                new Thread(r,"T2").start();

            }
        }
        Output:
            T2 added 1
            T1 added 1
            T2 added 2
            T1 added 2
            T1 added 3
            T1 printed [1, 1, 2, 2, 3, 3]
            T2 added 3
            T2 printed [1, 1, 2, 2, 3, 3]
        This is not the required output.
        While synchronized methods can make individual operations atomic, additional locking is required when multiple operations
        are combined into a compound action.